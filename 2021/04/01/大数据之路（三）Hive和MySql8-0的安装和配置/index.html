<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>大数据之路（三）Hive和MySql8.0的安装和配置 | Yeecoder's Blog</title><meta name="keywords" content="Hadoop"><meta name="author" content="Yeecoder"><meta name="copyright" content="Yeecoder"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Hive &amp; SparkHive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。为了解决直接使用Hadoop学习成本高、项目周期短MapReduce实现复杂查询难度大的问题而诞生并发展，Hive具有类SQL语句，便于上手和快速开发。Hive具有很好的可扩展性，即可自由扩展集群规模、延展性，即支持用户自定义函数和容错机制，即节点出现问题">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据之路（三）Hive和MySql8.0的安装和配置">
<meta property="og:url" content="http://example.com/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/index.html">
<meta property="og:site_name" content="Yeecoder&#39;s Blog">
<meta property="og:description" content="Hive &amp; SparkHive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。为了解决直接使用Hadoop学习成本高、项目周期短MapReduce实现复杂查询难度大的问题而诞生并发展，Hive具有类SQL语句，便于上手和快速开发。Hive具有很好的可扩展性，即可自由扩展集群规模、延展性，即支持用户自定义函数和容错机制，即节点出现问题">
<meta property="og:locale">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-04-01T00:55:42.000Z">
<meta property="article:modified_time" content="2021-04-19T05:26:23.187Z">
<meta property="article:author" content="Yeecoder">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-04-19 13:26:23'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">32</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yeecoder's Blog</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">大数据之路（三）Hive和MySql8.0的安装和配置</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-04-01T00:55:42.000Z" title="Created 2021-04-01 08:55:42">2021-04-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-04-19T05:26:23.187Z" title="Updated 2021-04-19 13:26:23">2021-04-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Hive-amp-Spark"><a href="#Hive-amp-Spark" class="headerlink" title="Hive &amp; Spark"></a>Hive &amp; Spark</h2><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。为了解决直接使用Hadoop学习成本高、项目周期短MapReduce实现复杂查询难度大的问题而诞生并发展，Hive具有类SQL语句，便于上手和快速开发。Hive具有很好的可扩展性，即可自由扩展集群规模、延展性，即支持用户自定义函数和容错机制，即节点出现问题仍可完成语句执行。</p>
<p>Spark是一个高速的、易用的和便于复杂分析的大数据处理框架，用于管理各种具有不同性质的数据集和数据源的大数据处理。可以将Hadoop集群中的应用在内存中的运行速度提升100倍，甚至能将应用在磁盘上的运行速度提升10倍。</p>
<h2 id="MySQL8-0的安装和配置"><a href="#MySQL8-0的安装和配置" class="headerlink" title="MySQL8.0的安装和配置"></a>MySQL8.0的安装和配置</h2><p>在CentOS7中使用yum安装MySQL，按照如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo yum localinstall https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm<br>sudo yum install mysql-community-server<br>sudo service mysqld start<br>sudo service mysqld status<br>sudo grep &#x27;temporary password&#x27; /var/log/mysqld.log<br></code></pre></td></tr></table></figure>

<p>使用上述命令中最后一条查到初始密码后，使用该密码登录MySQL，并修改密码。并给予root用户高级权限。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">ALTER user &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;Yeecoder1!&#x27;;<br>GRANT all ON *.* TO &#x27;root&#x27;@&#x27;localhost&#x27; WITH GRANT OPTION;<br>grant all on *.* to &#x27;root&#x27;@&#x27;localhost&#x27;；<br></code></pre></td></tr></table></figure>

<h2 id="Hive的安装和配置"><a href="#Hive的安装和配置" class="headerlink" title="Hive的安装和配置"></a>Hive的安装和配置</h2><p>下载Hive压缩包，进行解压和重命名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">tar -zxvf apache-hive-2.3.4-bin.tar.gz -C /opt/software<br>cd /opt/software<br>mv apache-hive-2.3.4-bin/ hive<br>rm -f apache-hive-2.3.4-bin.tar.gz<br></code></pre></td></tr></table></figure>

<p>修改hive的配置文件</p>
<p>首先将模板配置文件复制并重命名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd hive/conf<br>cp hive-env.sh.template hive-env.sh <br></code></pre></td></tr></table></figure>

<h3 id="hive-env-sh"><a href="#hive-env-sh" class="headerlink" title="hive-env.sh"></a>hive-env.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">HADOOP_HOME=/opt/software/hadoop<br>export HIVE_CONF_DIR=/opt/software/hive/conf<br>export HIVE_AUX_JARS_PATH=/opt/software/hive/lib<br></code></pre></td></tr></table></figure>

<h3 id="hive-site-sh"><a href="#hive-site-sh" class="headerlink" title="hive-site.sh"></a>hive-site.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs shell">&lt;configuration&gt;<br>    &lt;!-- WARNING!!! This file is auto generated for documentation purposes ONLY! --&gt;<br>    &lt;!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   --&gt;<br>    &lt;!-- WARNING!!! You must make your changes in hive-site.xml instead.         --&gt;<br>    &lt;!-- Hive Execution Parameters --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;hive.default.fileformat&lt;/name&gt;<br>        &lt;value&gt;TextFile&lt;/value&gt;<br>    &lt;/property&gt;<br>    &lt;property&gt;<br>        &lt;!--IP和端口改为自己的IP和端口，这里是连接数据库中onhive数据库，没有的话后面创建即可--&gt;<br>        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;<br>        &lt;value&gt;jdbc:mysql://192.168.187.101:3306/onhive&lt;/value&gt;<br>        &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;<br>    &lt;/property&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;<br>        &lt;!--最新版本连接MySQL的jar包 所有写com.mysql.cj.jdbc.Driver,如果是旧版本用com.mysql.jdbc.Driver--&gt;<br>        &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;<br>        &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;<br>    &lt;/property&gt;<br>    &lt;property&gt;<br>        &lt;!--连接MySQL的用户名--&gt;<br>        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;<br>        &lt;value&gt;root&lt;/value&gt;<br>        &lt;description&gt;username to use against metastore database&lt;/description&gt;<br>    &lt;/property&gt;<br>    &lt;property&gt;<br>        &lt;!--连接MySQL的密码--&gt;<br>        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;<br>        &lt;value&gt;Yeecoder1!&lt;/value&gt;<br>        &lt;description&gt;password to use against metastore database&lt;/description&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br></code></pre></td></tr></table></figure>

<p>完成上述操作后将层层解压后得到的连接MySQL的jar包放到hive/lib目录下，创建一个名为onhive的数据库。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">create database onhive;<br></code></pre></td></tr></table></figure>

<p>按顺序启动zookeeper，hdfs，yarn后，输入如下命令初始化hive。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">schematool -dbType mysql -initSchema<br></code></pre></td></tr></table></figure>

<p>如果没有报错则说明配置成功，在命令行窗口输入hive后可以进入到hive中进行查询等操作，表示hive完成配置。</p>
<p>使用如下命令启动Hive：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">\#首先启动Hive的metastore服务<br>hive --service metastore &amp;<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">\#其次启动Hive的HiveServer2服务<br>hive --service metastore &amp;<br></code></pre></td></tr></table></figure>

<p>这两个服务启动完成后命令行窗口不会产生变化，如果看到光标稳定闪动说明启动成功，再打开第三个命令行窗口使用Hive。</p>
<h2 id="Hive命令"><a href="#Hive命令" class="headerlink" title="Hive命令"></a>Hive命令</h2><p>创建数据库</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">create  database user_test;<br></code></pre></td></tr></table></figure>

<p>创建表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">create table user_sample(user_num bigint,user_name string,user_gender string,user_age int) row format delimited fields terminated by &#x27;,&#x27;; <br></code></pre></td></tr></table></figure>

<p>导入外部数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">\#前提是外部文件的内容格式按照表的格式<br>load data local inpath &#x27;LOCAL PATH&#x27; into table 目标表;<br></code></pre></td></tr></table></figure>

<p>查看数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">select * from user_sample;<br></code></pre></td></tr></table></figure>

<p>统计数据条数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">select count(*) from user_sample;<br></code></pre></td></tr></table></figure>

<h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">org.apache.hadoop.hive.metastore.HiveMetaException: Failed to get schema version.<br>Underlying cause: java.sql.SQLException : null,  message from server: &quot;Host &#x27;yeecoder1&#x27; is not allowed to connect to this MySQL server&quot;<br>SQL Error code: 1130<br>Use --verbose for detailed stacktrace.<br></code></pre></td></tr></table></figure>

<p>解决办法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">mysql -u root -pvmwaremysql&gt;use mysql;<br><span class="hljs-meta">mysql&gt;</span><span class="bash">update user <span class="hljs-built_in">set</span> host = <span class="hljs-string">&#x27;%&#x27;</span> <span class="hljs-built_in">where</span> user = <span class="hljs-string">&#x27;root&#x27;</span>;</span><br><span class="hljs-meta">mysql&gt;</span><span class="bash">select host, user from user;</span><br><span class="hljs-meta">mysql&gt;</span><span class="bash">FLUSH PRIVILEGES;</span><br></code></pre></td></tr></table></figure>

<h2 id="Spark的安装和配置"><a href="#Spark的安装和配置" class="headerlink" title="Spark的安装和配置"></a>Spark的安装和配置</h2><p>首先安装Scala并配置其环境。需要下载Scala,将其解压到/opt/software目录下并重命名。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">tar -zxvf tar scala-2.11.8.tgz -C /opt/software/<br>mv scala-2.11.8 scala<br></code></pre></td></tr></table></figure>

<p>修改环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim /etc/profile<br></code></pre></td></tr></table></figure>

<p>在该文件后追加以下内容，并重新加载环境变量。完成后在所有节点上都重复这部分操作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export SCALA_HOME=/opt/software/scala<br>export PATH=$PATH:$SCALA_HOME/bin<br></code></pre></td></tr></table></figure>

<p>下载Spark安装包，将其解压到/opt/software目录下并重命名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">tar -zxvf spark-2.0.0-bin-hadoop2.6.tgz -C /opt/software/<br>mv spark-2.0.0-bin-hadoop2.6 spark<br></code></pre></td></tr></table></figure>

<p>修改Spark的配置文件</p>
<h3 id="spark-env-sh"><a href="#spark-env-sh" class="headerlink" title="spark-env.sh"></a>spark-env.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">SPARK_LOCAL_IP=yeecoder1<br>SPARK_LOCAL_DIRS=/usr/local/spark<br>SPARK_MASTER_IP=yeecoder1<br>SPARK_MASTER_WEBUI_PORT=8080<br>export SPARK_MASTER_OPTS=&quot;-Dspark.deploy.defaultCores=4&quot;<br>SPARK_WORKER_CORES=2<br>SPARK_WORKER_MEMORY=1g<br>SPARK_WORKER_DIR=/usr/local/spark/work<br>export SPARK_WORKER_OPTS=&quot;-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.appDataTtl=604800&quot;<br>export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=3 -Dspark.history.fs.logDirectory=hdfs://yeecoder1/var/log/spark&quot;<br>SPARK_LOG_DIR=/usr/local/spark/logs<br>export JAVA_HOME=/usr/local/jdk<br>export SCALA_HOME=/usr/local/scala<br>export SPARK_MASTER_IP=yeecoder1<br>export SPARK_WORKER_MEMORY=1024m<br>export HADOOP_HOME=/usr/local/hadoop<br>export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/<br></code></pre></td></tr></table></figure>

<h3 id="spark-default-conf"><a href="#spark-default-conf" class="headerlink" title="spark-default.conf"></a>spark-default.conf</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">spark.eventLog.enabled          true<br>spark.eventLog.compress         true<br>spark.eventLog.dir              hdfs://yeecoder1/var/log/spark<br>spark.broadcast.blockSize       8m<br>spark.executor.cores            1<br>spark.executor.memory           512m<br>spark.executor.heartbeatInterval        20s<br>spark.files.fetchTimeout        120s<br>spark.task.maxFailures          6<br>spark.serializer                org.apache.spark.serializer.KryoSerializer<br>spark.kryoserializer.buffer.max         256m<br>spark.akka.frameSize            128<br>spark.default.parallelism       20<br>spark.network.timeout           300s<br>spark.speculation               true<br></code></pre></td></tr></table></figure>

<p>完成后在主节点的hdfs中新建文件夹/var/log/spark：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop fs -mkdir /var<br>hadoop fs -mkdir /var/log<br>hadoop fs -mkdir /var/log/spark<br></code></pre></td></tr></table></figure>

<h3 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">yeecoder1<br>yeecoder2<br>yeecoder3<br></code></pre></td></tr></table></figure>

<p>完成后将spark整个目录及其下属文件复制到其他节点上，并修改从节点上spark-env.sh中SPARK_LOCAL_IP为当前节点的IP或机器名。</p>
<p>进入主节点的spark/sbin目录后，启动Spark集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">start-all.sh<br></code></pre></td></tr></table></figure>

<p>如果执行完上述命令后进程中看不到Master和Worker进程，需要按照如下命令手动启动。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">\#启动master进程<br>start-master.sh<br>\#启动worker进程<br>\#主节点的worker进程<br>start-slave.sh spark://192.168.187.101:7077<br>\#从节点的worker进程<br>start-slave.sh spark://192.168.187.102:7077<br>start-slave.sh spark://192.168.187.103:7077<br></code></pre></td></tr></table></figure>

<p>如果启动成功，访问yeecoder1:8080出现可视化WebUI，其中可以看到有多少个worker节点以及他们的地址、处理器、内存使用情况，说明集群启动成功。</p>
<h3 id="踩坑2"><a href="#踩坑2" class="headerlink" title="踩坑2"></a>踩坑2</h3><p>当启用zooKeeper后再通过yeecoder1:8080的方式进入web页面时会显示404，似乎是zookeeper内置了jetty？</p>
<p>在执行spark-shell的时候出现如下warning信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable<br></code></pre></td></tr></table></figure>

<p>在spark的conf目录下，修改spark-env.sh文件加入LD_LIBRARY_PATH环境变量，值为hadoop的native库的路径。</p>
<h2 id="Spark基本操作例子"><a href="#Spark基本操作例子" class="headerlink" title="Spark基本操作例子"></a>Spark基本操作例子</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">\#进入spark命令行，即scala环境<br>spark shell<br>\#定义变量，并读取存放在HDFS中的文件<br>val textFile =sc.textFile(&quot;/myspark/testdata/README.md&quot;)<br>\#统计文件中出现Spark字符串的次数<br>textFile.filter(line =&gt;line.contains(&quot;Spark&quot;)).count()<br></code></pre></td></tr></table></figure>

<p>完成后可以进入网址yeecoder1:4040查看作业执行情况。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Yeecoder</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/">http://example.com/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%9B%9B%EF%BC%89flume%E5%92%8Ckafka%E5%92%8Csqoop%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">大数据之路（四）flume和kafka和sqoop的安装和配置</div></div></a></div><div class="next-post pull-right"><a href="/2021/03/31/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89Zookeeper%E5%92%8CHbase%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">大数据之路（二）Zookeeper和Hbase的安装和配置</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/03/31/大数据之路（一）CentOS7-Hadoop2-7-1安装和配置/" title="大数据之路（一）CentOS7+Hadoop2.7.1安装和配置"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-31</div><div class="title">大数据之路（一）CentOS7+Hadoop2.7.1安装和配置</div></div></a></div><div><a href="/2021/03/31/大数据之路（二）Zookeeper和Hbase的安装和配置/" title="大数据之路（二）Zookeeper和Hbase的安装和配置"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-31</div><div class="title">大数据之路（二）Zookeeper和Hbase的安装和配置</div></div></a></div><div><a href="/2021/04/03/大数据之路（四）flume和kafka和sqoop的安装和配置/" title="大数据之路（四）flume和kafka和sqoop的安装和配置"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-03</div><div class="title">大数据之路（四）flume和kafka和sqoop的安装和配置</div></div></a></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Yeecoder</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">32</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Yeecoder"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-amp-Spark"><span class="toc-number">1.</span> <span class="toc-text">Hive &amp; Spark</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE"><span class="toc-number">2.</span> <span class="toc-text">MySQL8.0的安装和配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">Hive的安装和配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#hive-env-sh"><span class="toc-number">3.1.</span> <span class="toc-text">hive-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hive-site-sh"><span class="toc-number">3.2.</span> <span class="toc-text">hive-site.sh</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive%E5%91%BD%E4%BB%A4"><span class="toc-number">4.</span> <span class="toc-text">Hive命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B8%A9%E5%9D%91"><span class="toc-number">4.1.</span> <span class="toc-text">踩坑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE"><span class="toc-number">5.</span> <span class="toc-text">Spark的安装和配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-env-sh"><span class="toc-number">5.1.</span> <span class="toc-text">spark-env.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-default-conf"><span class="toc-number">5.2.</span> <span class="toc-text">spark-default.conf</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slaves"><span class="toc-number">5.3.</span> <span class="toc-text">slaves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B8%A9%E5%9D%912"><span class="toc-number">5.4.</span> <span class="toc-text">踩坑2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%BE%8B%E5%AD%90"><span class="toc-number">6.</span> <span class="toc-text">Spark基本操作例子</span></a></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/04/24/MongoDB/" title="MongoDB"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MongoDB"/></a><div class="content"><a class="title" href="/2021/04/24/MongoDB/" title="MongoDB">MongoDB</a><time datetime="2021-04-24T02:27:52.000Z" title="Created 2021-04-24 10:27:52">2021-04-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/04/23/CentOS7-Nginx%E9%83%A8%E7%BD%B2Django%E9%A1%B9%E7%9B%AE/" title="CentOS7+Nginx部署Django项目"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CentOS7+Nginx部署Django项目"/></a><div class="content"><a class="title" href="/2021/04/23/CentOS7-Nginx%E9%83%A8%E7%BD%B2Django%E9%A1%B9%E7%9B%AE/" title="CentOS7+Nginx部署Django项目">CentOS7+Nginx部署Django项目</a><time datetime="2021-04-23T03:34:44.000Z" title="Created 2021-04-23 11:34:44">2021-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/04/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%9B%9B%EF%BC%89flume%E5%92%8Ckafka%E5%92%8Csqoop%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（四）flume和kafka和sqoop的安装和配置"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大数据之路（四）flume和kafka和sqoop的安装和配置"/></a><div class="content"><a class="title" href="/2021/04/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E5%9B%9B%EF%BC%89flume%E5%92%8Ckafka%E5%92%8Csqoop%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（四）flume和kafka和sqoop的安装和配置">大数据之路（四）flume和kafka和sqoop的安装和配置</a><time datetime="2021-04-02T21:34:26.000Z" title="Created 2021-04-03 05:34:26">2021-04-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（三）Hive和MySql8.0的安装和配置"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大数据之路（三）Hive和MySql8.0的安装和配置"/></a><div class="content"><a class="title" href="/2021/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%89%EF%BC%89Hive%E5%92%8CMySql8-0%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（三）Hive和MySql8.0的安装和配置">大数据之路（三）Hive和MySql8.0的安装和配置</a><time datetime="2021-04-01T00:55:42.000Z" title="Created 2021-04-01 08:55:42">2021-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/03/31/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89Zookeeper%E5%92%8CHbase%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（二）Zookeeper和Hbase的安装和配置"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大数据之路（二）Zookeeper和Hbase的安装和配置"/></a><div class="content"><a class="title" href="/2021/03/31/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%BA%8C%EF%BC%89Zookeeper%E5%92%8CHbase%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/" title="大数据之路（二）Zookeeper和Hbase的安装和配置">大数据之路（二）Zookeeper和Hbase的安装和配置</a><time datetime="2021-03-31T13:24:49.000Z" title="Created 2021-03-31 21:24:49">2021-03-31</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Yeecoder</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>